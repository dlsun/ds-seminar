---
layout: landing
---

# Data Science Seminar

## Grading

Please enroll in DATA 472 for 1 unit, on a CR/NC grading basis.

To earn a CR grade, you are expected to:

- attend all seminars
- do the reading
- complete the assignment associated with each reading

## Readings

## Winter 2023

### Week 7: February 22

In this next exercise you'll be working with a team, again, to revisit the kidney disease dataset. Please read the instructions for the second assignment and access the data at the following link, and come prepared to next week's class:

[https://drive.google.com/drive/folders/1vXFloq65bmXzwWfB-K6VMJtnWbRy52I3](https://drive.google.com/drive/folders/1vXFloq65bmXzwWfB-K6VMJtnWbRy52I3)

### Week 6: February 15

One of the dangers of AI and Machine Learning technologies becoming ubiquitous is that they inevitably become the tools in product marketing, fundraising, and attention-grabbing campaigns.  As data scientists we do not always control how our work is presented to others and in what form.  As consumers we may want to recognize when claims of AI use exceed plausibility, or spurious.

AI/ML researchers and sociologists started using the term "AI snake oil" to discuss situations when AI technology is being sold for unsuitable purposes, or when the marketing claims of AI input into a company's product are dubious.

Looking at the problem from another angle, we as data scientists, machine learning experts and AI researchers must understand the limitations of the tools we use to analyze data, make predictions, and obtain insight from data.  We must be able to separate the real contributions and capabilities of AI/ML systems from the claims made in public space.

So, let's take a look at how AI snake oil works and how to recognize it.

For next week's assignment, watch  Arvind Narayanan's talk "How to Recognize AI Snake Oil" available here:  [https://www.cs.princeton.edu/news/how-recognize-ai-snake-oil](https://www.cs.princeton.edu/news/how-recognize-ai-snake-oil)
(1 hour 37 minutes)

The slides for the talk can be found here: [https://www.cs.princeton.edu/~arvindn/talks/MIT-STS-AI-snakeoil.pdf](https://www.cs.princeton.edu/~arvindn/talks/MIT-STS-AI-snakeoil.pdf)

For some additional insight and takes, you can also watch this University of Oxford virtual panel on Fake AI, snake oil, pseudoscience and hype by a group of authors of the book "Fake AI, pseudosicence, snake oil and hype":
[https://www.youtube.com/watch?v=w1f0Sj-st9g&ab_channel=OxfordInternetInstitute%2CUniversityofOxford](https://www.youtube.com/watch?v=w1f0Sj-st9g&ab_channel=OxfordInternetInstitute%2CUniversityofOxford)
(1 hour 4 minutes)

In preparation for the discussion, break into groups of 4 people each and discuss the following questions:

* What is AI snake oil? How would you define it for yourselves?
* What are the signs of AI snake oil? How can you spot them?
* How do you draw the line between legitimate claims of contributions of AI/ML/data science methods to a marketable product (e.g., a software system), and the AI snake oil-style claims?
* What do you feel are the obligations of data scientists/ML engineers w.r.t. to flawed AI claims made about their work by others?
* Where is the boundary between harmless and harmful when it comes down to flawed AI claims?

In class, we will discuss each question in turn, each group is expected to have a summary of thoughts on each question prepared for sharing with the rest of the Fellowship.

### Week 5: February 8

In this next exercise you'll be working with a team, again, to analyze some data in an attempt to do some classification. Please read the instructions and access the data at the following link, and come prepared to next week's class:

[https://drive.google.com/drive/folders/1vXFloq65bmXzwWfB-K6VMJtnWbRy52I3](https://drive.google.com/drive/folders/1vXFloq65bmXzwWfB-K6VMJtnWbRy52I3)

### Week 4: February 1

In the next week, we will discuss tooling.

You need to pick a partner to research one of two technologies for data science: R or Python. Before class make sure you know which tool you're researching and that the assignments are balanced across all pairs of students.

The R group will research the advantages of:

* R
* R Markdown

The Python group will research the advantages of:

* Python
* Jupyter notebooks

Come prepared to discuss and debate the advantages of your assigned technology.

### Week 3: January 25

By this class, in your same groups of three from the activity on January 18, you should pick two data science tools from the following list to compare and contrast with respect to **reproducibility**. What are the pros? What are the cons? Is one of them clearly better than the other? Why?

Come to class prepared to give a 5-minute presentation on what you come up with.

* RStudio

* PyCharm

* Jupyter

* Google Colab

* Amazon Web Services

* Google Docs

* Github

* GitLab

* Slack

* Dropbox

* Tableau

* LaTeX

* Microsoft Office

* RMarkdown

### Week 2: January 18

Our first unit is on **reproducibility**. Please read the following before this class and come prepared to discuss them both in terms of their content and how you feel they relate to your experiences and knowledge of data science:

- [https://www.nature.com/articles/533452a](https://www.nature.com/articles/533452a)

- [https://www.vox.com/future-perfect/21504366/science-replication-crisis-peer-review-statistics](https://www.vox.com/future-perfect/21504366/science-replication-crisis-peer-review-statistics)

- [https://arxiv.org/pdf/2011.10098.pdf](https://arxiv.org/pdf/2011.10098.pdf)

**Please don't look at the following docs until class today!**

Group 1: [https://docs.google.com/document/d/1zlgi44LB8L8-5-gCTknCy54pKT_BjaqAVf7CoNvBIIU/edit?usp=sharing](https://docs.google.com/document/d/1zlgi44LB8L8-5-gCTknCy54pKT_BjaqAVf7CoNvBIIU/edit?usp=sharing)

Group 2: [https://docs.google.com/document/d/1PsQwkE8OoAg9h7Q8LP_DZ135U5Z29hEd7lk7fUJCfd0/edit?usp=sharing](https://docs.google.com/document/d/1PsQwkE8OoAg9h7Q8LP_DZ135U5Z29hEd7lk7fUJCfd0/edit?usp=sharing)

### Week 1: January 11

## Fall 2022

The theme of the readings for Fall 2022 is **the past**.

### Week 1: September 21

### Week 2: September 28

Hypothesis testing is a core part of many statistics classes. But where did the ideas such as the p-value, Type I error, and power come from? This reading reviews the turbulent history of hypothesis testing in the 20th century.

#### Required Reading:

- [Chapters 10 and 11](http://dlsun.github.io/ds-seminar/readings/LadyTastingTea-HypothesisTesting.pdf) from David Salsburg (2001). _The lady tasting tea: How statistics revolutionized science in the twentieth century_. Macmillan.

#### Additional Resources:

- Erich Lehmann (1993). [The Fisher, Neyman-Pearson Theories of Testing Hypotheses: One Theory or Two?](https://www.jstor.org/stable/2291263). (You should be able to download a PDF when you are on the Cal Poly network or VPN.)
- Erich Lehmann (2011). [Fisher, Neyman, and the Creation of Classical Statistics](https://link.springer.com/book/10.1007/978-1-4419-9500-1).
- [Oral History Interviews with David Blackwell](https://www.youtube.com/watch?v=Xo_YYxsFF6Y&list=PLCwE4GdJdVRIU1j2-nzpxOIi3XSNEZ3qv) (Youtube playlist).

#### Assignment:

In your assigned group of 6 students:
- Pair 1 should prepare slides discussing Fisher's contributions to hypothesis testing.
- Pair 2 should prepare slides discussing Neyman's (and Pearson's) contributions to hypothesis testing.
- Pair 3 should prepare slides comparing and contrasting the two approaches.

### Week 3: October 5

In the early to mid 1900s, the field of eugenics - the idea that some groups or people are inherently genetically inferior - was a mainstream and well-respected scientific pursuit.  Many of the foundational ideas of classic statistics were developed in conjunction with eugenics applications.  In the modern era, now that these ideas have been rejected as racist/classist/etc, how should we regard the influential people and ideas that came out of that movement?

#### Required Reading:

- [This twitter thread](https://threadreaderapp.com/thread/1268392721275744256.html) by famous statistician Daniela Witten, which initiated a change to a major statistics award.
- [Scientific Priestcraft](https://github.com/dlsun/ds-seminar/blob/master/readings/Superior_Ch3.pdf), Chapter 3 of "Superior: The Return of Race Science" by Angela Saini.

#### Assignment:

We ask you to think carefully about the practice of re-contextualizing scientific contributions in light of modern ethics.  Questions to consider:

- Does removing accolates like the Fisher Prize harm the target and/or his family?  Should the scientific contributions be considered in isolation, and honored, regardless of what else the individual did?
- Does this approach truly create a more welcoming/diverse scientific community?  Or does it discourage or hinder others from contributing to scientific progress, for fear of personal scrutiny?
- Does it remove objectivity from statistical methodology?
- Does it help us prevent similar mistakes in the future?

In your assigned group of 6 students:
- Pair 1 should track down more examples of events like the Fisher Prize renaming: Can you find historical figures related to data science whose ethics are currently in question?  Can you find examples of honors or accolades being removed from these people (or discussions suggesting such)? 
- Pair 2 should collect, summarize, and present arguments **against** re-contextualizing scientific contributions in light of modern ethics.     
- Pair 3 should collect, summarize, and present arguments **for** re-contextualizing scientific contributions in light of modern ethics.

### Week 4: October 12

We will look at the Frequentist vs. Bayes debate! Not only does this debate pertain to how you think and do your statistics and data science, but also to some of your ways of thinking every day! Please come prepared to defend both, although we want you will be asked to take a side in class.

#### Required Reading:

- New York Times Article: [The Odds, Continually Updated](readings/The%20Odds,%20Continually%20Updated%20-%20The%20New%20York%20Times.pdf)
- [Frequentist and Bayesian Approaches in Statistics](https://www.probabilisticworld.com/frequentist-bayesian-approaches-inferential-statistics)
- Efron, B. (2005). [Bayesians, frequentists, and scientists](https://dlsun.github.io/ds-seminar/readings/Bayesians,%20Frequentists,%20and%20Scientists.pdf). _Journal of the American Statistical Association_, 100(469), 1-5.
- [The Boxer, the Wrestler, and the Coin Flip: A Paradox of Robust Bayesian Inference and Belief Functions](http://www.stat.columbia.edu/~gelman/research/published/augie4.pdf) Andrew Gelman, The American Statistician, May 2006, Vol. 60, No. 2
- xkcd comic on [Frequentists vs. Bayesians](https://xkcd.com/1132/)

Here are some additional readings that might be of interest.

- MIT Lecture Notes: [Comparison of frequentist and Bayesian inference](https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/MIT18_05S14_Reading20.pdf).
- Efron, B. (1986). [Why isn't everyone a Bayesian?](https://dlsun.github.io/ds-seminar/readings/Why%20Isn't%20Everyone%20a%20Bayesian.pdf) _The American Statistician_, 40(1), 1-5.
- Andrew Gelman's blog post: [Why I Don't Like Bayesian Statistics](https://statmodeling.stat.columbia.edu/2008/04/01/problems_with_b/). (This is an April Fools' Joke written by a famous Bayesian statistician. However, it contains some good ideas.)

#### Assignment:

We ask you to think carefully about these two sides: Frequentist and Bayes.  Questions to consider:

- What are the strengths and weaknesses of each?
- Is it possible be a little bit of both? Why or why not?
- Think about your own beliefs about how probability and the likelihood of events work. In your day-to-day life (when not doing statistics or data science), do you tend to be more frequentist or bayesian? 

In your assigned group of 6 students:
- Pair 1 should organize and present the strengths of the Frequentist side and the weaknesses of the Bayesian side, as they pertain to statistics and data science work.
- Pair 2 should organize and present the strengths of the Bayesian side and the weaknesses of the Frequentist side, as they pertain to statistics and data science work.     
- Pair 3 should comment on how these two sides pertain to day-to-day life, and whether your position on them in this context should be related to your position on them in the context of your work. Be sure to think carefully and thoroughly here. Your comments might also include similarities between the two sides in certain situations. 

### Week 5: October 19

We will read a classic paper by Leo Breiman entitled "Statistical Modeling: The Two Cultures."   The PDF linked below also contains comments by leading statisticians and data scientists which will give you more ideas as you prepare your presentations.

#### Required Reading:

- Leo Breiman: [Statistical Modeling: The Two Cultures (with comments and a rejoinder by the author)](readings/breiman.pdf)

This paper by Efron can be seen as an update to Breiman's paper 20 years later -- it is not required reading but might be interesting for you to read over:

- Efron, B. (2020). [Prediction, Estimation, and Attribution](https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1762613) _Journal of the American Statistical Association_.

#### Assignment:

In your assigned group of 6 students:
- Pair 1 should organize and present the strengths of the "data modeling" culture.
- Pair 2 should organize and present the strengths of the "algorithmic modeling" culture.
- Pair 3 should compare and constrast the two cultures.

### Week 6: October 26

We will discuss the past and future of Artificial Intelligence (AI). 

#### Required Reading:

- [Deep Learning's Diminish Returns](https://spectrum.ieee.org/deep-learning-computational-cost)
- [Probability of an Approaching AI Winter](https://towardsdatascience.com/probability-of-an-approaching-ai-winter-c2d818fb338a)


#### Assignment:

In your assigned group of 6 students: 
- Pair 1 should review the two papers.
- Pair 2 should make the argument why AI is the best thing since peanut butter and jelly and why investment in AI will keep growing.
- Pair 3 should make the argument that history will repeat itself, reality will crush expectations, and we will head for another AI winter.


### Week 7: November 2

We are starting a three-week stretch devoted to the ideas and technologies behind working with big data. Our first discussion is about relational databases, their history and their role in bringing forth our ability to work with large quantities of data.  To that end, you will read two sets of articles.

The first set of articles gives you some historic perspective on the development of the **relational data model** and **relational databases**. The articles in this set are:

- [E.F. Codd. A Relational Model of Data For Large Shared Data Banks, Communications of the ACM, June 1970] ( https://www.seas.upenn.edu/~zives/03f/cis550/codd.pdf)
- [E.F. Codd. The 12 Rules, (excert from "Is your database fully relational?", Computerworld, Oct 1985, reprinted](https://reldb.org/c/index.php/twelve-rules/)
- [Important Papers: Codd and the Relational Model. Two Bit History blog, Dec 2017](https://twobithistory.org/2017/12/29/codd-relational-model.html)

The Codd papers provide historic descriptions of the ideas behind the modern relational databases. The blog post puts some of the information contained in these papers in the overall context.

The second set of papers comes from a sequence of meetings conducted by the database research and industry community over the course of the late 20th and early 21st century. The meetings served as the community reflection points on the progress of the field of relational databases (and the field of databases in general) over the years. They also attempted to identify future challenges that the database technology and the database community needed to meet. The papers are co-authored by who's who in the area of database management systems.  The papers in this series are:

- [Erich Neuhold and Michael Stonebreaker Future Directions in DBMS Research, 1988](http://users.csc.calpoly.edu/~dekhtyar/560-Fall2012/papers/Stonebraker88.pdf)
- [A. Silberschatz, M. Stonebraker, J. Ullman (Eds.), Database Research: Achievements and Opportunities into the 21st Century, 1995](http://users.csc.calpoly.edu/~dekhtyar/560-Fall2012/papers/DB-research1995.pdf)
- [A. Silberschatz, S. Zdonik et al, Strategic Directions in Database Systems - Breaking out of the Box, 1996](http://users.csc.calpoly.edu/~dekhtyar/560-Fall2012/papers/StrategicDirections.pdf)
- [P. Bernstein et al., The Asilomar Report on Database Research, 1998](http://users.csc.calpoly.edu/~dekhtyar/560-Fall2012/papers/Asilomar_DB_98.pdf)
- [S. Abiteboul et al., The Lowell Database Research Self Assessment, 2003](http://users.csc.calpoly.edu/~dekhtyar/560-Fall2012/papers/lowell-report2005.pdf)
- [R. Agrawal et al., The Claremont Report on Database Research, Communications of the ACM 2009](http://users.csc.calpoly.edu/~dekhtyar/560-Fall2012/papers/claremont-report2009.pdf)
- [D. Agrawal, Challenges and Opportunities with Big Data, 2012](http://users.csc.calpoly.edu/~dekhtyar/560-Fall2012/papers/bigdatawhitepaper.pdf)

**This is a lot of reading. Please, read the instructions below carefully.**

The roles for this week's assignment are:

- **Role 1: Archeologists.** Students in this role will present information about the development the ideas behind modern (relational) database management systems and will discuss the importance of these ideas to today's data science.
- **Role 2: Supporters.** Students in this role will discuss what the database community _got right_ about its challenges and the problems that it needs to tackle in a modern world.
- **Role 3: Detractors.** Students in this role will discuss where the database community _missed_. What errors of omission and commission did the DB community commit? (Errors of omisison - something important about today's world of working with data, that the community missed. Errors of commission - something the DB community thought would be a big challenge, that was not).

### Week 8: November 9

We will discuss the rise and "fall" of Hadoop... and future of Hadoop. 

#### Required Reading:
Everyone should read in detail the following:

- [Background on CAP Theorem](https://en.wikipedia.org/wiki/CAP_theorem)
- [Google's MapReduce Paper](https://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf)
- [Hadoop: The Chronicle of an Expected Decline](https://www.singlestore.com/blog/hadoop-the-chronicle-of-an-expected-decline/)

#### Assignment:
The "decline" of Hadoop is documented, and so it is not my intention to have you discuss why this happened. It is an interesting topic but not our focus. I'll share a bit of my own experiences with Hadoop at the beginning of seminar since it came about during my graduate school days, and I've been along for the ride ever since. 

In your assigned group of 6 students: 
- Pair 1 should provide summaries of the CAP Theorem, MapReduce Paper, and the blog style article.
- Pair 2 should discuss how Hadoop can be thrive as expectations and the technology mature (i.e., in a plateau of productivity phase). Specifically, they should focus on explaining and expanding on the third article's optimism for Hadoop. For example, the authors mention technologies maturing around Hadoop: optimized data formats (ORC, Parquet) and query engines (Impala, Presto, Dremel). This pair should also discuss and expand upon the emerging best practices, and should make a general case for the long-term viability of Hadoop ecosystem.
- Pair 3 should discuss and expand upon why the third article's optimism for Hadoop is incorrect. They likewise should go through the article and prepare specific counterpoints to the author's claims of a "plateau of productivity" future for Hadoop.


### Week 9: November 16
Everyone needs to read the following:
- [A brief History of the Internet](https://dl.acm.org/doi/pdf/10.1145/1629607.1629613)
- [What is Web 2.0?](https://www.oreilly.com/pub/a/web2/archive/what-is-web-20.html) (make sure to read all the pages)
- [Semantic web](https://en.wikipedia.org/wiki/Semantic_Web)
- [Chicken Farms on the Semantic Web](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4445616&casa_token=rQj24Wp1StkAAAAA:Z6z7-0ehk4PFab16P8LDUh2yoN53kPykBl7s9o7or4kQ7Nrw2f02kubxHFxHnmjjTKdDYvOkYw&tag=1)

In your assigned group of 6:
- Pair 1 presents fundamental forces (social, economical, political) that were crucial to development of the World Wide Web
- Pair 2 explain the differences between Web 1.0 and Web 2.0. Use examples and products from your own life and interaction. Name the ways in which current technologies exptend from Web 2.0 enabling concepts. 
- Pair 3 explain the semantic Web. How are things likely to change based on this in the near future? Use examples.

Everyone: be sure to look up terms and products that you're reading about which you may not be familiar with (too old or discontinued). Teams need to be explain the terms in the papers that have to do with their subject, if asked during their presentations.